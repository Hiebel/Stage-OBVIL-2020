{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enchant\n",
    "import glob\n",
    "from lxml import etree\n",
    "import os\n",
    "from enchant.checker import SpellChecker\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de lecture de fichier au format XML-TEI qui renvoie le contenu textuel de la balise \"text\"\n",
    "def lire_TEI_XML(input_file):\n",
    "    namespace = \"{http://www.tei-c.org/ns/1.0}text\"\n",
    "    parser = etree.XMLParser(recover=True)\n",
    "    root = etree.parse(input_file, parser)\n",
    "    contenu = \"\"\n",
    "    for texte in root.iter(namespace):\n",
    "        textes = texte.itertext()\n",
    "        for cpt, el in enumerate(textes):\n",
    "            if el != \"\\n\":\n",
    "                contenu += el\n",
    "                contenu += \" \"\n",
    "        contenu = contenu.replace(\"\\n\", \" \")\n",
    "    return contenu\n",
    "\n",
    "# fonction qui prend en entrée une chaine de caractères\n",
    "# et qui renvoie cette chaine corrigée par le correcteur \n",
    "# donné en paramètre ainsi qu'une ligne à ecrire dans un csvsous le format \n",
    "# \"erreur,suggestion,contexte,fichier\"\n",
    "# Le correcteur est un objet de type SpellChecker \n",
    "# On a besoin du correcteur en entrée pour ne pas le recréer à chaque fichier quand on corrige un corpus\n",
    "# puisque l'on souhaite potentiellement personnaliser le correcteur en ajoutant les entrée d'une liste\n",
    "def correction(texte, chkr, fichier=\"\"):\n",
    "    # A tester : ne pas corriger les noms propres\n",
    "    lignes = []\n",
    "    chkr.set_text(texte)\n",
    "    for err in chkr:\n",
    "        ligne = []\n",
    "        ligne.append(err.word)\n",
    "        if len(chkr.suggest(err.word)) > 0:\n",
    "            err.replace(chkr.suggest(err.word)[0])   # [0] signifie prendre le candidat ayant la distance de Levenshtein la plus proche\n",
    "            # Si deux candidats ont une distance égale, je ne sais pas quel est le critère qui choisit le candidat\n",
    "            ligne.append(chkr.suggest(err.word)[0])\n",
    "        else:\n",
    "            ligne.append(\"Pas de correction trouvée\")\n",
    "        contexte = err.leading_context(50) + err.word + err.trailing_context(50)\n",
    "        contexte = contexte.replace(\"\\n\", \" \")\n",
    "        ligne.append(contexte)\n",
    "        ligne.append(fichier)\n",
    "        lignes.append(ligne)\n",
    "    return chkr.get_text(), lignes\n",
    "\n",
    "\n",
    "# Fonction qui prend en entrée un dossier de fichiers (.txt ou XML-TEI) et génère \n",
    "# des fichiers corrigés automatiquement dans le dossier de sortie défini en paramètre\n",
    "# ainsi qu'un fichier tsv contenant la liste des erreurs avec leur contexte\n",
    "def corriger_dossier(chemin_dossier_corpus, chemin_dossier_sortie):\n",
    "\n",
    "    # Création du dossier de sortie s'il n'existe pas\n",
    "    if not os.path.exists(chemin_dossier_sortie):\n",
    "        os.makedirs(chemin_dossier_sortie)\n",
    "\n",
    "    # Instance du vérificateur orthographique (la langue est entre parenthèses)\n",
    "    chkr = SpellChecker(\"fr\")\n",
    "\n",
    "    # Chargement de la liste d'erreurs personnalisée\n",
    "    charger_liste = True\n",
    "\n",
    "\n",
    "    if charger_liste:\n",
    "        # Chemin du fichier csv sous la forme erreur,correction\n",
    "        chemin_liste = \"Correction_automatique.csv\"\n",
    "\n",
    "        # Le fichier contient-il des entetes ? La variable est à True si oui, False sinon\n",
    "        presence_entetes = True\n",
    "\n",
    "        # Si le fichier contient des entêtes (presence_entetes = True), il faut les définir ici\n",
    "        # La première valeur de la liste sera le nom de la colonne des formes erronées, et la deuxième celle des formes correctes\n",
    "        liste_entetes = [\"Erreur observée\", \"Correction proposée\"]\n",
    "\n",
    "        delimiteur = \"\\t\"\n",
    "\n",
    "        with open(chemin_liste, \"r\", encoding=\"utf-8\", newline='') as csvfile:\n",
    "            if presence_entetes == False:\n",
    "                reader = csv.reader(csvfile, delimiter=delimiteur)\n",
    "                for row in reader:\n",
    "                    chkr.replace_always(row[0], row[1])\n",
    "                    # ajouter le nouveau mot dans le dictionnaire\n",
    "                    chkr.add(row[1])\n",
    "            else:\n",
    "                reader = csv.DictReader(csvfile, delimiter=delimiteur)\n",
    "                for row in reader:\n",
    "                    chkr.replace_always(row[liste_entetes[0]], row[liste_entetes[1]])\n",
    "                    # ajouter le nouveau mot dans le dictionnaire\n",
    "                    chkr.add(row[liste_entetes[1]])\n",
    "\n",
    "    # Chemin du fichier tsv qui contiendra la liste des erreurs avec la correction proposée et le fichier d'origine\n",
    "    fichier_erreurs = \"%s/erreurs.csv\" % chemin_dossier_sortie\n",
    "\n",
    "    with open(fichier_erreurs, \"w\", encoding=\"utf-8\", newline='') as csvfile:\n",
    "        fieldnames = [\"Erreur_détectée\", \"Correction_proposée\", \"Contexte\", \"Fichier\"]\n",
    "        spamwriter = csv.writer(csvfile, delimiter=\"\\t\")\n",
    "        spamwriter.writerow(fieldnames)\n",
    "\n",
    "        for fichier in glob.glob(\"%s/*\" % chemin_dossier_corpus):\n",
    "            extension = fichier.split(\".\")[-1]\n",
    "            if extension == \"txt\" or extension == \"xml\":\n",
    "                print(\"Traitement du fichier %s\" % fichier)\n",
    "                nom_fichier = fichier.split(\"\\\\\")[1]\n",
    "                sans_extension = nom_fichier.split(\".\")[0]\n",
    "                if extension == \"xml\":\n",
    "                    contenu = lire_TEI_XML(fichier)\n",
    "                else:\n",
    "                    with open(fichier, 'r', encoding = \"utf-8\") as fin:\n",
    "                        contenu = fin.read()\n",
    "                        \n",
    "                correction_contenu, lignes_erreurs = correction(contenu, chkr, sans_extension)\n",
    "                for ligne in lignes_erreurs:\n",
    "                    spamwriter.writerow(ligne)\n",
    "                with open(\"%s/%s_correction.txt\" % (chemin_dossier_sortie, sans_extension), 'w', encoding=\"utf-8\") as fout:\n",
    "                    fout.write(correction_contenu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossier_corpus = \"Test\"\n",
    "dossier_sortie = \"%s_script_correction\" % dossier_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement du fichier Test\\tt.txt\n"
     ]
    }
   ],
   "source": [
    "corriger_dossier(dossier_corpus, dossier_sortie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
