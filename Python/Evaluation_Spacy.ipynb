{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from lxml import etree\n",
    "import spacy\n",
    "from spacy.gold import GoldParse\n",
    "from spacy.scorer import Scorer\n",
    "\n",
    "# récupérer les annotations manuelles sur un fichier au format \"Inline XML\"\n",
    "def recup_annotations_manuelles(fichier):\n",
    "    annotations = []\n",
    "    parser = etree.XMLParser(recover=True)\n",
    "    root = etree.parse(fichier, parser)\n",
    "    balise_EN = \"de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity\"\n",
    "    \n",
    "    for el in root.iter(balise_EN):\n",
    "        annotations.append((int(el.attrib[\"begin\"]), int(el.attrib[\"end\"]), el.attrib[\"value\"]))\n",
    "    return annotations\n",
    "\n",
    "# récupérer les annotations et le texte à partir d'un fichier au format json particulier (exporter format UIMA CAS JSON sur INCEPTION)\n",
    "def recup_annotations_texte(fichier):\n",
    "    dico = lire_json(fichier_texte_ann_manuelles)\n",
    "    annots = dico[\"_views\"][\"_InitialView\"][\"NamedEntity\"]\n",
    "    annotations = []\n",
    "    for ann in annots:\n",
    "        annotations.append((ann[\"begin\"], ann[\"end\"], ann[\"value\"]))\n",
    "    texte = dico[\"_referenced_fss\"][\"1\"][\"sofaString\"]\n",
    "    return annotations, texte\n",
    "\n",
    "# récupérer le texte d'un fichier \".txt\"\n",
    "def recup_texte(fichier):\n",
    "    with open(fichier, \"r\", encoding=\"utf-8\") as f:\n",
    "        texte = f.read()\n",
    "    return texte\n",
    "\n",
    "# récupérer les annotations d'un fichier csv avec les entêtes \"Indice_Début\", \"Indice Fin\", \"Tag\"\n",
    "def recup_annotations_csv(fichier):\n",
    "    annotations = []\n",
    "    with open(fichier, \"r\", encoding=\"utf-8\", newline=\"\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile, delimiter=\",\")\n",
    "        for row in reader:\n",
    "            #print(row['Tag'], row['Indice_Début'], row['Indice_Fin'])\n",
    "            annotations.append((int(row['Indice_Début']), int(row['Indice_Fin']), row['Tag']))\n",
    "\n",
    "    return annotations\n",
    "\n",
    "# lecture d'un fichier json à partir de son chemin\n",
    "# renvoie le dictionnaire correspondant\n",
    "def lire_json(fichier):\n",
    "    with open(fichier, \"r\", encoding=\"utf-8\") as fin:\n",
    "        dic = json.load(fin)\n",
    "    return dic\n",
    "\n",
    "# fonction d'évaluation pour Spacy\n",
    "# prend en argument le model utilisé et les donnees à tester, sous la forme d'une liste de tuples (texte, annotations attendues)\n",
    "def evaluate(ner_model, donnees):\n",
    "    #scorer = Scorer()\n",
    "    for input_, annot in donnees:\n",
    "        scorer = Scorer()\n",
    "        doc_gold_text = ner_model.make_doc(input_)\n",
    "        # Gold : valeurs de référence\n",
    "        gold = GoldParse(doc_gold_text, entities=annot)\n",
    "        # Valeurs prédites par le modèle\n",
    "        pred_value = ner_model(input_)\n",
    "        #print(pred_value)\n",
    "        #for ent in pred_value.ents:\n",
    "            #print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "        scorer.score(pred_value, gold)\n",
    "    return scorer.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96206\n",
      "224\n",
      "227\n"
     ]
    }
   ],
   "source": [
    "chemin_fichier = \"Evaluation/Fichiers/5408048\"\n",
    "fichier_texte_ann_manuelles = \"%s_texte_manuelles.json\" % chemin_fichier\n",
    "\n",
    "fichier_text_corr = \"%s_correction.txt\" % chemin_fichier\n",
    "\n",
    "fichier_an_auto = \"%s_annotations.csv\" % chemin_fichier\n",
    "fichier_an_auto_corr = \"%s_annotations_correction.csv\" % chemin_fichier\n",
    "\n",
    "\n",
    "manuelles, texte = recup_annotations_texte(fichier_texte_ann_manuelles)\n",
    "\n",
    "texte_corr = recup_texte(fichier_text_corr)\n",
    "print(len(texte_corr))\n",
    "auto = recup_annotations_csv(fichier_an_auto)\n",
    "print(len(auto))\n",
    "auto_corr = recup_annotations_csv(fichier_an_auto_corr)\n",
    "print(len(auto_corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "versions = [\n",
    "    (texte2, manuelles)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "ner_model = spacy.load('fr_core_news_sm')\n",
    "results = evaluate(ner_model, versions)\n",
    "print(results[\"ents_per_type\"])\n",
    "print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Evaluation/Fichiers/5408048_correction.txt\"\n",
    "\n",
    "with open(test, \"r\", encoding=\"utf-8\") as fin:\n",
    "    texte2 = fin.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100, 104, 'PER'), (110, 112, 'PER'), (116, 123, 'ORG'), (127, 144, 'ORG'), (223, 233, 'ORG'), (258, 271, 'PER'), (307, 316, 'PER'), (318, 326, 'PER'), (330, 369, 'LOC'), (717, 722, 'LOC')]\n",
      "[(35, 38, 'ORG'), (110, 112, 'LOC'), (116, 123, 'ORG'), (127, 144, 'ORG'), (223, 233, 'ORG'), (255, 263, 'PER'), (306, 315, 'PER'), (317, 325, 'PER'), (329, 368, 'LOC'), (716, 721, 'LOC')]\n"
     ]
    }
   ],
   "source": [
    "print(auto_corr[:10])\n",
    "print(auto[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"je m'appelle Nico et je viens de Paris\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"jeee m'appelle Nico et je viens de Pariss\"\n",
    "\n",
    "\"je m'appelle Nico et je viens de Paris\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_manuelles = []\n",
    "\n",
    "for annot in manuelles:\n",
    "    l = list(annot)\n",
    "    l.append(texte[annot[0]:annot[1]])\n",
    "    json_manuelles.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"annotations_manuelles.json\", \"w\", encoding=\"utf-8\") as fout:\n",
    "    fout.write(json.dumps(json_manuelles, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_spacy = []\n",
    "\n",
    "for annot in auto:\n",
    "    l = list(annot)\n",
    "    l.append(texte[annot[0]:annot[1]])\n",
    "    json_spacy.append(l)\n",
    "    \n",
    "\n",
    "with open(\"annotations_spacy.json\", \"w\", encoding=\"utf-8\") as fout:\n",
    "    fout.write(json.dumps(json_spacy, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_spacy_correction = []\n",
    "\n",
    "for annot in auto_corr:\n",
    "    l = list(annot)\n",
    "    l.append(texte[annot[0]:annot[1]])\n",
    "    json_spacy_correction.append(l)\n",
    "    \n",
    "with open(\"annotations_spacy_corrige.json\", \"w\", encoding=\"utf-8\") as fout:\n",
    "    fout.write(json.dumps(json_spacy_correction, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
